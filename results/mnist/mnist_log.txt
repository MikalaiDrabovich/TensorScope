2018-07-25 03:24:58.502242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-07-25 03:24:58.502689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1404] Found device 0 with properties: 
name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705
pciBusID: 0000:01:00.0
totalMemory: 5.94GiB freeMemory: 5.44GiB
2018-07-25 03:24:58.502702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1483] Adding visible gpu devices: 0
2018-07-25 03:24:58.692690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:964] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-07-25 03:24:58.692736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:970]      0 
2018-07-25 03:24:58.692743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:983] 0:   N 
2018-07-25 03:24:58.692943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Created TensorFlow device (/device:GPU:0 with 5209 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)
2018-07-25 03:24:58.693195: E tensorflow/core/common_runtime/gpu/gpu_device.cc:228] Illegal GPUOptions.experimental.num_dev_to_dev_copy_streams=0 set to 1 instead.
/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
INFO:tensorflow:Using default config.
I0725 03:24:58.744868 140077068973824 tf_logging.py:115] Using default config.
INFO:tensorflow:Using config: {'_model_dir': '/home/ndr/work_july/july24/TensorScope/reproduce_results/mnist/mnist_model', '_is_chief': True, '_log_step_count_steps': 100, '_num_worker_replicas': 1, '_master': '', '_tf_random_seed': None, '_global_id_in_cluster': 0, '_task_type': 'worker', '_session_config': None, '_save_checkpoints_steps': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f65d3a7abe0>, '_train_distribute': None, '_save_checkpoints_secs': 600, '_service': None, '_evaluation_master': '', '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_num_ps_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_task_id': 0, '_device_fn': None}
I0725 03:24:58.745247 140077068973824 tf_logging.py:115] Using config: {'_model_dir': '/home/ndr/work_july/july24/TensorScope/reproduce_results/mnist/mnist_model', '_is_chief': True, '_log_step_count_steps': 100, '_num_worker_replicas': 1, '_master': '', '_tf_random_seed': None, '_global_id_in_cluster': 0, '_task_type': 'worker', '_session_config': None, '_save_checkpoints_steps': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f65d3a7abe0>, '_train_distribute': None, '_save_checkpoints_secs': 600, '_service': None, '_evaluation_master': '', '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_num_ps_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_task_id': 0, '_device_fn': None}
INFO:tensorflow:Calling model_fn.
I0725 03:24:58.780703 140077068973824 tf_logging.py:115] Calling model_fn.
INFO:tensorflow:Done calling model_fn.
I0725 03:24:59.069568 140077068973824 tf_logging.py:115] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I0725 03:24:59.070585 140077068973824 tf_logging.py:115] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I0725 03:24:59.202175 140077068973824 tf_logging.py:115] Graph was finalized.
2018-07-25 03:24:59.202546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1483] Adding visible gpu devices: 0
2018-07-25 03:24:59.202608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:964] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-07-25 03:24:59.202615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:970]      0 
2018-07-25 03:24:59.202637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:983] 0:   N 
2018-07-25 03:24:59.202762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5209 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)
INFO:tensorflow:Running local_init_op.
I0725 03:24:59.357879 140077068973824 tf_logging.py:115] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I0725 03:24:59.363903 140077068973824 tf_logging.py:115] Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into /home/ndr/work_july/july24/TensorScope/reproduce_results/mnist/mnist_model/model.ckpt.
I0725 03:24:59.572834 140077068973824 tf_logging.py:115] Saving checkpoints for 0 into /home/ndr/work_july/july24/TensorScope/reproduce_results/mnist/mnist_model/model.ckpt.
2018-07-25 03:24:59.821964: I tensorflow/stream_executor/dso_loader.cc:151] successfully opened CUDA library libcupti.so.9.2 locally
INFO:tensorflow:cross_entropy = 2.290447, learning_rate = 1e-04, train_accuracy = 0.12
I0725 03:25:02.207676 140077068973824 tf_logging.py:115] cross_entropy = 2.290447, learning_rate = 1e-04, train_accuracy = 0.12
INFO:tensorflow:loss = 2.290447, step = 0
I0725 03:25:02.208151 140077068973824 tf_logging.py:115] loss = 2.290447, step = 0
Step 0/10(14) completed in 2.5432 seconds.
Session graph and metadata parsed in 0.0042 seconds
Step 1/10(14) completed in 0.0690 seconds.
Timeline saved in /home/ndr/work_july/july24/TensorScope/results/mnist/timeline_at_step_2.json
Session graph and metadata parsed in 0.0045 seconds
Step 2/10(14) completed in 0.0130 seconds.
Session graph and metadata parsed in 0.0044 seconds
Step 3/10(14) completed in 0.0128 seconds.
Session graph and metadata parsed in 0.0044 seconds
Step 4/10(14) completed in 0.0130 seconds.
Session graph and metadata parsed in 0.0045 seconds
Step 5/10(14) completed in 0.0119 seconds.
Session graph and metadata parsed in 0.0044 seconds
Step 6/10(14) completed in 0.0122 seconds.
Session graph and metadata parsed in 0.0051 seconds
Step 7/10(14) completed in 0.0123 seconds.
Session graph and metadata parsed in 0.0047 seconds
Step 8/10(14) completed in 0.0120 seconds.
Session graph and metadata parsed in 0.0045 seconds
Step 9/10(14) completed in 0.0128 seconds.
Session graph and metadata parsed in 0.0046 seconds
Step 10/10(14) completed in 0.0123 seconds.
Session is closed

Sanity check: total time for 10 steps: 0.181 sec., 1 step avg. time:  18138.6 microsec., 1 step avg. time captured in metadata: 10305.3 microsec., number of unique ops: 113

*** Brief summary ***

Top-1 ops (0.9%)	4.0 ms (38.4%)
Top-2 ops (1.8%)	4.8 ms (46.4%)
Top-3 ops (2.7%)	5.6 ms (54.2%)
Top-5 ops (4.4%)	7.0 ms (68.0%)
Top-8 ops (7.1%)	7.8 ms (75.5%)
Top-14 ops (12.4%)	8.8 ms (85.4%)
Top-23 ops (20.4%)	9.6 ms (93.0%)
Top-40 ops (35.4%)	10.0 ms (96.8%)
Top-67 ops (59.3%)	10.2 ms (98.7%)
Top-113 ops (100.0%)	10.3 ms (100.0%)

*** I/O tensor shapes are saved to /home/ndr/work_july/july24/TensorScope/results/mnist/data.tsv ***

2018-07-25 03:25:02.462603: E tensorflow/core/kernels/data/cache_dataset_ops.cc:593] The calling iterator did not fully read the dataset we were attempting to cache. In order to avoid unexpected truncation of the sequence, the current [partially cached] sequence will be dropped. This can occur if you have a sequence similar to `dataset.cache().take(k).repeat()`. Instead, swap the order (i.e. `dataset.take(k).cache().repeat()`)
